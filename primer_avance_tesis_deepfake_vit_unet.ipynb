{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8302499",
   "metadata": {},
   "source": [
    "# Primer Avance de Código — Tesis de Detección y Segmentación de Deepfakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4201ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm torchvision matplotlib opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8523bc",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c941148",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import timm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59166213",
   "metadata": {},
   "source": [
    "## Definir arquitectura híbrida Vision Transformer + U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f08eaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ViT_UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True, features_only=True)\n",
    "        vit_channels = self.vit.feature_info.channels()[-1]\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(vit_channels, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.vit(x)[-1]\n",
    "        mask = self.decoder(features)\n",
    "        return mask\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37fa634",
   "metadata": {},
   "source": [
    "## Crear dataset sintético"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f228df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FakeFaceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, n=200, img_size=224):\n",
    "        self.n = n\n",
    "        self.img_size = img_size\n",
    "        self.transform = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(0.5, 0.5)\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.new('RGB', (self.img_size, self.img_size), color='gray')\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        x0, y0 = np.random.randint(50, 150, size=2)\n",
    "        r = np.random.randint(20, 50)\n",
    "        draw.ellipse((x0, y0, x0+r, y0+r), fill='white')\n",
    "        mask = Image.new('L', (self.img_size, self.img_size), color=0)\n",
    "        draw2 = ImageDraw.Draw(mask)\n",
    "        draw2.ellipse((x0, y0, x0+r, y0+r), fill=1)\n",
    "        img_t = self.transform(img)\n",
    "        mask_t = torch.from_numpy(np.array(mask)).unsqueeze(0).float()\n",
    "        return img_t, mask_t\n",
    "\n",
    "train_ds = FakeFaceDataset(n=100)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cc7caa",
   "metadata": {},
   "source": [
    "## Entrenar modelo por 3 épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2380bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ViT_UNet().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    total_loss = 0\n",
    "    for imgs, masks in train_loader:\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, masks)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/3 — Loss: {total_loss/len(train_loader):.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040c4cc4",
   "metadata": {},
   "source": [
    "## Visualizar imágenes, máscaras reales y predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9068e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "imgs, masks = next(iter(train_loader))\n",
    "imgs, masks = imgs.to(device), masks.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = model(imgs)\n",
    "\n",
    "def show(im, title=''):\n",
    "    arr = im.squeeze().cpu().numpy()\n",
    "    plt.imshow(arr, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(4):\n",
    "    plt.subplot(4,3,3*i+1); show(imgs[i], 'Imagen')\n",
    "    plt.subplot(4,3,3*i+2); show(masks[i], 'Máscara real')\n",
    "    plt.subplot(4,3,3*i+3); show(preds[i], 'Predicción')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}